#!/usr/bin/env python3
"""
–ê–ª–≥–æ—Ä–∏—Ç–º –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç—É—Ä—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
"""

import asyncio
import os
import cv2
import numpy as np
from scipy import ndimage
from skimage import feature, filters, measure
from utils.receipt_analyzer import straighten_receipt

def analyze_texture_features(image: np.ndarray) -> dict:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç—É—Ä—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ç–µ–∫—Å—Ç–∞
    """
    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # 1. –ê–Ω–∞–ª–∏–∑ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –±–∏–Ω–∞—Ä–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (LBP)
        lbp = feature.local_binary_pattern(gray, 8, 1, method='uniform')
        lbp_hist, _ = np.histogram(lbp.ravel(), bins=10, range=(0, 10))
        lbp_hist = lbp_hist.astype(float) / lbp_hist.sum()
        lbp_entropy = -np.sum(lbp_hist * np.log2(lbp_hist + 1e-10))
        
        # 2. –ê–Ω–∞–ª–∏–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ (Sobel)
        sobel_x = filters.sobel_h(gray)
        sobel_y = filters.sobel_v(gray)
        gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
        
        gradient_mean = np.mean(gradient_magnitude)
        gradient_std = np.std(gradient_magnitude)
        gradient_entropy = -np.sum(gradient_magnitude * np.log2(gradient_magnitude + 1e-10))
        
        # 3. –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç—É—Ä–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        # –ö–æ–Ω—Ç—Ä–∞—Å—Ç
        contrast = np.std(gray)
        
        # –≠–Ω–µ—Ä–≥–∏—è (—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç—å)
        hist, _ = np.histogram(gray, bins=256, range=(0, 256))
        hist = hist.astype(float) / hist.sum()
        energy = np.sum(hist**2)
        
        # –≠–Ω—Ç—Ä–æ–ø–∏—è
        entropy = -np.sum(hist * np.log2(hist + 1e-10))
        
        # 4. –ê–Ω–∞–ª–∏–∑ –ª–∏–Ω–∏–π –∏ –∫—Ä–∞–µ–≤
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
        gradient_direction = np.arctan2(sobel_y, sobel_x)
        direction_hist, _ = np.histogram(gradient_direction, bins=36, range=(-np.pi, np.pi))
        direction_entropy = -np.sum(direction_hist * np.log2(direction_hist + 1e-10))
        
        # 5. –ê–Ω–∞–ª–∏–∑ —Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (–ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω–∞—è)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º box-counting –º–µ—Ç–æ–¥
        def box_counting(image, box_sizes):
            counts = []
            for size in box_sizes:
                # –£–º–µ–Ω—å—à–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                h, w = image.shape
                new_h, new_w = h // size, w // size
                if new_h == 0 or new_w == 0:
                    continue
                
                resized = cv2.resize(image, (new_w, new_h))
                # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–ø—É—Å—Ç—ã—Ö —è—á–µ–µ–∫
                count = np.sum(resized > 0)
                counts.append(count)
            return counts
        
        binary_image = (gray > 128).astype(np.uint8)
        box_sizes = [1, 2, 4, 8, 16, 32]
        counts = box_counting(binary_image, box_sizes)
        
        if len(counts) > 1:
            # –í—ã—á–∏—Å–ª—è–µ–º –Ω–∞–∫–ª–æ–Ω –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            log_sizes = np.log(box_sizes[:len(counts)])
            log_counts = np.log(counts)
            if len(log_sizes) > 1:
                fractal_dim = -np.polyfit(log_sizes, log_counts, 1)[0]
            else:
                fractal_dim = 0
        else:
            fractal_dim = 0
        
        # 6. –ê–Ω–∞–ª–∏–∑ —Å–∏–º–º–µ—Ç—Ä–∏–∏
        # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è —Å–∏–º–º–µ—Ç—Ä–∏—è
        h, w = gray.shape
        top_half = gray[:h//2, :]
        bottom_half = gray[h//2:, :]
        if bottom_half.shape[0] != top_half.shape[0]:
            bottom_half = bottom_half[:top_half.shape[0], :]
        
        horizontal_symmetry = 1.0 - np.mean(np.abs(top_half - np.flipud(bottom_half))) / 255.0
        
        # 7. –ê–Ω–∞–ª–∏–∑ —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        # FFT –∞–Ω–∞–ª–∏–∑
        fft = np.fft.fft2(gray)
        fft_shift = np.fft.fftshift(fft)
        magnitude_spectrum = np.log(np.abs(fft_shift) + 1)
        
        # –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –æ–±–ª–∞—Å—Ç—å —Å–ø–µ–∫—Ç—Ä–∞
        h, w = magnitude_spectrum.shape
        center_h, center_w = h // 2, w // 2
        center_region = magnitude_spectrum[center_h-20:center_h+20, center_w-20:center_w+20]
        center_energy = np.sum(center_region**2)
        
        # –ü–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
        mask = np.ones((h, w), dtype=bool)
        mask[center_h-20:center_h+20, center_w-20:center_w+20] = False
        peripheral_region = magnitude_spectrum[mask]
        peripheral_energy = np.sum(peripheral_region**2)
        
        regularity_ratio = center_energy / (peripheral_energy + 1e-10)
        
        return {
            'lbp_entropy': lbp_entropy,
            'gradient_mean': gradient_mean,
            'gradient_std': gradient_std,
            'gradient_entropy': gradient_entropy,
            'contrast': contrast,
            'energy': energy,
            'entropy': entropy,
            'edge_density': edge_density,
            'direction_entropy': direction_entropy,
            'fractal_dimension': fractal_dim,
            'horizontal_symmetry': horizontal_symmetry,
            'regularity_ratio': regularity_ratio
        }
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–µ–∫—Å—Ç—É—Ä—ã: {e}")
        return {}

def calculate_texture_chaos_score(features: dict) -> float:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—â–∏–π –∏–Ω–¥–µ–∫—Å —Ö–∞–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç—É—Ä–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
    """
    if not features:
        return 0.0
    
    try:
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        chaos_components = []
        
        # 1. –≠–Ω—Ç—Ä–æ–ø–∏—è (–≤—ã—Å–æ–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è = –±–æ–ª—å—à–µ —Ö–∞–æ—Å–∞)
        if 'entropy' in features:
            entropy_norm = min(features['entropy'] / 8.0, 1.0)  # 8 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è –¥–ª—è 8-–±–∏—Ç–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            chaos_components.append(entropy_norm * 0.15)
        
        # 2. LBP —ç–Ω—Ç—Ä–æ–ø–∏—è
        if 'lbp_entropy' in features:
            lbp_norm = min(features['lbp_entropy'] / 3.0, 1.0)  # 3 - –ø—Ä–∏–º–µ—Ä–Ω—ã–π –º–∞–∫—Å–∏–º—É–º –¥–ª—è LBP
            chaos_components.append(lbp_norm * 0.15)
        
        # 3. –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è
        if 'gradient_entropy' in features:
            grad_ent_norm = min(features['gradient_entropy'] / 10.0, 1.0)
            chaos_components.append(grad_ent_norm * 0.10)
        
        # 4. –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ (—Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π = —Ö–∞–æ—Å)
        if 'direction_entropy' in features:
            dir_ent_norm = min(features['direction_entropy'] / 5.0, 1.0)
            chaos_components.append(dir_ent_norm * 0.10)
        
        # 5. –§—Ä–∞–∫—Ç–∞–ª—å–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (–≤—ã—Å–æ–∫–∞—è = —Å–ª–æ–∂–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ = —Ö–∞–æ—Å)
        if 'fractal_dimension' in features:
            fractal_norm = min(features['fractal_dimension'] / 2.0, 1.0)
            chaos_components.append(fractal_norm * 0.10)
        
        # 6. –û–±—Ä–∞—Ç–Ω–∞—è —Å–∏–º–º–µ—Ç—Ä–∏—è (–Ω–∏–∑–∫–∞—è —Å–∏–º–º–µ—Ç—Ä–∏—è = —Ö–∞–æ—Å)
        if 'horizontal_symmetry' in features:
            asym_norm = 1.0 - features['horizontal_symmetry']
            chaos_components.append(asym_norm * 0.10)
        
        # 7. –û–±—Ä–∞—Ç–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å (–Ω–∏–∑–∫–∞—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å = —Ö–∞–æ—Å)
        if 'regularity_ratio' in features:
            irregular_norm = 1.0 / (1.0 + features['regularity_ratio'])
            chaos_components.append(irregular_norm * 0.10)
        
        # 8. –ü–ª–æ—Ç–Ω–æ—Å—Ç—å –∫—Ä–∞–µ–≤ (–≤—ã—Å–æ–∫–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å = —Å–ª–æ–∂–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
        if 'edge_density' in features:
            edge_norm = min(features['edge_density'] * 10, 1.0)
            chaos_components.append(edge_norm * 0.10)
        
        # 9. –í–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
        if 'gradient_std' in features and 'gradient_mean' in features:
            if features['gradient_mean'] > 0:
                grad_var_norm = min(features['gradient_std'] / features['gradient_mean'], 1.0)
                chaos_components.append(grad_var_norm * 0.10)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        total_chaos = sum(chaos_components) if chaos_components else 0.0
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–µ–ª–∏–Ω–µ–π–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–∏–π
        if total_chaos < 0.3:
            total_chaos = total_chaos * 0.5  # –°–Ω–∏–∂–∞–µ–º –¥–ª—è –Ω–∏–∑–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        elif total_chaos > 0.7:
            total_chaos = 0.7 + (total_chaos - 0.7) * 2.0  # –£—Å–∏–ª–∏–≤–∞–µ–º –¥–ª—è –≤—ã—Å–æ–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        
        return min(total_chaos, 1.0)
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞ —Ö–∞–æ—Å–∞ —Ç–µ–∫—Å—Ç—É—Ä—ã: {e}")
        return 0.0

async def test_texture_based_analysis():
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç—É—Ä—ã
    """
    print("üé® –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç—É—Ä—ã")
    print("=" * 60)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—á–∞—Ç–Ω—ã–µ —á–µ–∫–∏
    print("\nüìÑ –ê–Ω–∞–ª–∏–∑ –ø–µ—á–∞—Ç–Ω—ã—Ö —á–µ–∫–æ–≤:")
    print("-" * 40)
    
    machine_folder = "–æ–±—É—á–µ–Ω–∏–µ/–ú–∞—à–∏–Ω–∞"
    machine_files = [f for f in os.listdir(machine_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    
    printed_scores = []
    
    for filename in machine_files:
        filepath = os.path.join(machine_folder, filename)
        
        try:
            with open(filepath, 'rb') as f:
                image_bytes = f.read()
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            nparr = np.frombuffer(image_bytes, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                continue
            
            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
            height, width = image.shape[:2]
            max_width = 1000
            if width > max_width:
                scale = max_width / width
                new_width = max_width
                new_height = int(height * scale)
                image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
            
            # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º
            straightened = straighten_receipt(image)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç—É—Ä—É
            features = analyze_texture_features(straightened)
            chaos_score = calculate_texture_chaos_score(features)
            printed_scores.append(chaos_score)
            
            print(f"  {filename}: {chaos_score:.3f}")
            
        except Exception as e:
            print(f"  {filename}: –æ—à–∏–±–∫–∞ - {e}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä—É–∫–æ–ø–∏—Å–Ω—ã–µ —á–µ–∫–∏
    print("\n‚úçÔ∏è –ê–Ω–∞–ª–∏–∑ —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö —á–µ–∫–æ–≤:")
    print("-" * 40)
    
    hand_folder = "–æ–±—É—á–µ–Ω–∏–µ/–†—É–∫–∞"
    hand_files = [f for f in os.listdir(hand_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    
    handwritten_scores = []
    
    for filename in hand_files:
        filepath = os.path.join(hand_folder, filename)
        
        try:
            with open(filepath, 'rb') as f:
                image_bytes = f.read()
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            nparr = np.frombuffer(image_bytes, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                continue
            
            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
            height, width = image.shape[:2]
            max_width = 1000
            if width > max_width:
                scale = max_width / width
                new_width = max_width
                new_height = int(height * scale)
                image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
            
            # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º
            straightened = straighten_receipt(image)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç—É—Ä—É
            features = analyze_texture_features(straightened)
            chaos_score = calculate_texture_chaos_score(features)
            handwritten_scores.append(chaos_score)
            
            print(f"  {filename}: {chaos_score:.3f}")
            
        except Exception as e:
            print(f"  {filename}: –æ—à–∏–±–∫–∞ - {e}")
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if printed_scores and handwritten_scores:
        print(f"\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π:")
        print(f"–ü–µ—á–∞—Ç–Ω—ã–µ —á–µ–∫–∏:")
        print(f"  –°—Ä–µ–¥–Ω–∏–π: {np.mean(printed_scores):.3f}")
        print(f"  –ú–µ–¥–∏–∞–Ω–Ω—ã–π: {np.median(printed_scores):.3f}")
        print(f"  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {np.std(printed_scores):.3f}")
        print(f"  –î–∏–∞–ø–∞–∑–æ–Ω: {np.min(printed_scores):.3f} - {np.max(printed_scores):.3f}")
        
        print(f"\n–†—É–∫–æ–ø–∏—Å–Ω—ã–µ —á–µ–∫–∏:")
        print(f"  –°—Ä–µ–¥–Ω–∏–π: {np.mean(handwritten_scores):.3f}")
        print(f"  –ú–µ–¥–∏–∞–Ω–Ω—ã–π: {np.median(handwritten_scores):.3f}")
        print(f"  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {np.std(handwritten_scores):.3f}")
        print(f"  –î–∏–∞–ø–∞–∑–æ–Ω: {np.min(handwritten_scores):.3f} - {np.max(handwritten_scores):.3f}")
        
        # –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
        print(f"\nüéØ –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞:")
        
        all_scores = printed_scores + handwritten_scores
        all_labels = ['printed'] * len(printed_scores) + ['handwritten'] * len(handwritten_scores)
        
        thresholds = np.arange(0.1, 1.0, 0.05)
        best_threshold = 0.5
        best_accuracy = 0
        
        for threshold in thresholds:
            correct = 0
            total = len(all_scores)
            
            for score, label in zip(all_scores, all_labels):
                predicted = 'pro' if score > threshold else 'flash'
                expected = 'pro' if label == 'handwritten' else 'flash'
                if predicted == expected:
                    correct += 1
            
            accuracy = correct / total
            print(f"  –ü–æ—Ä–æ–≥ {threshold:.2f}: —Ç–æ—á–Ω–æ—Å—Ç—å {accuracy:.3f}")
            
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_threshold = threshold
        
        print(f"\nüèÜ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {best_threshold:.2f} (—Ç–æ—á–Ω–æ—Å—Ç—å: {best_accuracy:.3f})")
        
        return best_threshold, best_accuracy
    
    return 0.5, 0.0

if __name__ == "__main__":
    asyncio.run(test_texture_based_analysis())
